{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Analizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import spacy\n",
    "import sqlite3\n",
    "import lemminflect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLP = spacy.load(\"en_core_web_sm\", exclude = ['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATABASE_FILENAME = 'word_cefr_minified.db'\n",
    "\n",
    "conn = sqlite3.connect(DATABASE_FILENAME)\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate functions and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABBREVIATION_MAPPING = {\n",
    "    \"'m\": \"am\",\n",
    "    \"'s\": \"is\",\n",
    "    \"'re\": \"are\",\n",
    "    \"'ve\": \"have\",\n",
    "    \"'d\": \"had\",\n",
    "    \"n't\": \"not\",\n",
    "    \"'ll\": \"will\"\n",
    "}\n",
    "\n",
    "DIFFICULTY_MAPPING_REVERSE = {\n",
    "    1: 'A1',\n",
    "    2: 'A2',\n",
    "    3: 'B1',\n",
    "    4: 'B2',\n",
    "    5: 'C1',\n",
    "    6: 'C2'\n",
    "}\n",
    "\n",
    "\n",
    "def is_punctuation(word: str) -> bool:\n",
    "    return not word and not any(char.isalpha() for char in word)\n",
    "\n",
    "\n",
    "def custom_tokenize_text(text: str) -> list[tuple[str, str, str]]:\n",
    "    text = text.replace(\"â€™\", \"'\")\n",
    "    tokens = []\n",
    "    doc = NLP(text)\n",
    "    for token in doc:\n",
    "        word = token.text.lower().strip()\n",
    "        word_pos = token.tag_\n",
    "        proposed_lemma = token._.lemma().lower()\n",
    "\n",
    "        abbreviation_form = ABBREVIATION_MAPPING.get(word)\n",
    "        if abbreviation_form:\n",
    "            word = abbreviation_form\n",
    "            lemma = word\n",
    "        elif proposed_lemma is None:\n",
    "            lemma = word.lower()\n",
    "        else:\n",
    "            lemma = proposed_lemma\n",
    "\n",
    "        tokens.append((word, lemma, word_pos))\n",
    "\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def fetch_word_pos_level_tokens(word_pos_tokens_set: set[tuple[str, str]]) -> dict[tuple[str, str], float]:\n",
    "    placeholders = ','.join(['(?, ?)' for _ in range(len(word_pos_tokens_set))])\n",
    "\n",
    "    cursor.execute('''\n",
    "        WITH word_pos_tags(word, pos_tag) AS (\n",
    "            VALUES {}\n",
    "        )\n",
    "        SELECT\n",
    "            word_pos_tags.word,\n",
    "            word_pos_tags.pos_tag,\n",
    "            COALESCE(\n",
    "                AVG(CASE WHEN pt.tag = word_pos_tags.pos_tag THEN wp.level END),\n",
    "                AVG(wp.level)\n",
    "            ) AS avg_level\n",
    "        FROM word_pos_tags\n",
    "        JOIN words w ON word_pos_tags.word = w.word\n",
    "        JOIN word_pos wp ON w.word_id = wp.word_id\n",
    "        JOIN pos_tags pt ON wp.pos_tag_id = pt.tag_id\n",
    "        GROUP BY word_pos_tags.word, word_pos_tags.pos_tag\n",
    "    '''.format(placeholders), [item for sublist in word_pos_tokens_set for item in sublist])\n",
    "\n",
    "    word_pos_level_tokens = cursor.fetchall()\n",
    "\n",
    "    return {(word, pos_tag): float(avg_level) for word, pos_tag, avg_level in word_pos_level_tokens}\n",
    "\n",
    "\n",
    "def get_word_pos_tokens_set(tokens: list[tuple[str, str, str]]) -> set[tuple[str, str]]:\n",
    "    return {(token[0], token[2]) for token in tokens if not is_punctuation(token[1])}\n",
    "\n",
    "\n",
    "def get_levels_tokens(tokens: list[tuple[str, str, str]]) -> list[tuple[str, str, str, float]]:\n",
    "    word_pos_set = get_word_pos_tokens_set(tokens)\n",
    "    word_pos_unique_level_tokens = fetch_word_pos_level_tokens(word_pos_set)\n",
    "\n",
    "    word_pos_level_tokens = []\n",
    "    for token in tokens:\n",
    "        word, lemma, word_pos = token\n",
    "\n",
    "        level = word_pos_unique_level_tokens.get((word, word_pos))\n",
    "        if level is None:\n",
    "            level = 0\n",
    "\n",
    "        word_pos_level_tokens.append((word, lemma, word_pos, level))\n",
    "\n",
    "    return word_pos_level_tokens\n",
    "\n",
    "\n",
    "def get_word_level_count_statistic(level_tokens: list[tuple[str, str, str, float]]) -> list[int]:\n",
    "    difficulty_levels_count = [0] * 6\n",
    "    for token in level_tokens:\n",
    "        level = round(token[3])\n",
    "        if level:\n",
    "            difficulty_levels_count[level - 1] += 1\n",
    "\n",
    "    return difficulty_levels_count\n",
    "\n",
    "\n",
    "def get_word_level_count_statistic_unique(level_tokens: list[tuple[str, str, str, float]]) -> list[int]:\n",
    "    processed_word_pos_set = set()\n",
    "    difficulty_levels_count = [0] * 6\n",
    "    for token in level_tokens:\n",
    "        level = round(token[3])\n",
    "        to_check_tuple = (token[0], token[2])\n",
    "        if level and not to_check_tuple in processed_word_pos_set:\n",
    "            processed_word_pos_set.add(to_check_tuple)\n",
    "            difficulty_levels_count[level - 1] += 1\n",
    "\n",
    "    return difficulty_levels_count\n",
    "\n",
    "\n",
    "def get_not_found_words(level_tokens: list[tuple[str, str, str, float]]) -> set[str]:\n",
    "    not_found_words = set()\n",
    "    for token in level_tokens:\n",
    "        if not token[3] and token[0] and all(char.isalpha() for char in token[0]):\n",
    "            not_found_words.add(token[0])\n",
    "\n",
    "    return not_found_words\n",
    "\n",
    "\n",
    "def filter_for_desired_level(level_tokens: list[tuple[str, str, str, float]],\n",
    "                            min_level: float, max_level: float = 6) -> set[tuple[str, str, str, float]]:\n",
    "    filtered_tokens = set()\n",
    "    for token in level_tokens:\n",
    "        level = token[3]\n",
    "        if level >= min_level and level <= max_level:\n",
    "            filtered_tokens.add(token)\n",
    "\n",
    "    return filtered_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: ChatGPT 3.5\n",
    "input_text = \"\"\"\n",
    "In the heart of every forest, a hidden world thrives among the towering trees. Trees, \n",
    "those silent giants, are more than just passive observers of nature's drama; they are \n",
    "active participants in an intricate dance of life.\n",
    "\n",
    "Did you know that trees communicate with each other? It's not through words or gestures \n",
    "like ours, but rather through a complex network of fungi that connect their roots \n",
    "underground. This network, often called the \"wood wide web,\" allows trees to share \n",
    "nutrients, water, and even warnings about potential threats.\n",
    "\n",
    "But trees are not just generous benefactors; they are also masters of adaptation. Take \n",
    "the mighty sequoias, for example, towering giants that have stood the test of time for \n",
    "thousands of years. These giants have evolved thick, fire-resistant bark to withstand \n",
    "the frequent wildfires of their native California.\n",
    "\n",
    "And speaking of longevity, did you know that some trees have been around for centuries, \n",
    "witnessing history unfold? The ancient bristlecone pines of the American West, for \n",
    "instance, can live for over 5,000 years, making them some of the oldest living organisms \n",
    "on Earth.\n",
    "\n",
    "So the next time you find yourself wandering through a forest, take a moment to appreciate \n",
    "the remarkable world of trees. They may seem like silent spectators, but their lives are \n",
    "full of fascinating stories waiting to be discovered.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLP: 318 ms\n",
      "CEFR levels: 3 ms\n",
      "------------------------------\n",
      "Text length: 1370\n",
      "Total tokens: 275\n"
     ]
    }
   ],
   "source": [
    "start_time_nlp = time.time()\n",
    "tokens = custom_tokenize_text(input_text)\n",
    "\n",
    "print(\"NLP:\", round((time.time() - start_time_nlp) * 1000), \"ms\")\n",
    "\n",
    "start_time_cefr = time.time()\n",
    "level_tokens = get_levels_tokens(tokens)\n",
    "print(\"CEFR levels:\", round((time.time() - start_time_cefr) * 1000), \"ms\")\n",
    "\n",
    "print('-' * 30)\n",
    "\n",
    "print(\"Text length:\", len(input_text))\n",
    "print(\"Total tokens:\", len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD                      \tLEMMA                     \tPOS\tLEVEL\tCEFR\n",
      "-------------------------------------------------------------------------------------\n",
      "in                        \tin                        \tIN\t1.00\tA1\n",
      "the                       \tthe                       \tDT\t1.00\tA1\n",
      "heart                     \theart                     \tNN\t1.00\tA1\n",
      "of                        \tof                        \tIN\t1.00\tA1\n",
      "every                     \tevery                     \tDT\t1.00\tA1\n",
      "forest                    \tforest                    \tNN\t2.00\tA2\n",
      ",                         \t,                         \t,\t0.00\tNone\n",
      "a                         \ta                         \tDT\t1.00\tA1\n",
      "hidden                    \thidden                    \tJJ\t3.00\tB1\n",
      "world                     \tworld                     \tNN\t1.00\tA1\n",
      "thrives                   \tthrive                    \tVBZ\t5.86\tC2\n",
      "among                     \tamong                     \tIN\t2.00\tA2\n",
      "the                       \tthe                       \tDT\t1.00\tA1\n",
      "towering                  \ttower                     \tVBG\t1.00\tA1\n",
      "trees                     \ttree                      \tNNS\t1.00\tA1\n",
      ".                         \t.                         \t.\t0.00\tNone\n",
      "trees                     \ttree                      \tNNS\t1.00\tA1\n",
      ",                         \t,                         \t,\t0.00\tNone\n",
      "those                     \tthose                     \tDT\t1.00\tA1\n",
      "silent                    \tsilent                    \tJJ\t3.00\tB1\n",
      "giants                    \tgiant                     \tNNS\t3.00\tB1\n",
      ",                         \t,                         \t,\t0.00\tNone\n",
      "are                       \tbe                        \tVBP\t1.00\tA1\n",
      "more                      \tmuch                      \tJJR\t1.67\tA2\n",
      "than                      \tthan                      \tIN\t1.00\tA1\n",
      "just                      \tjust                      \tRB\t1.00\tA1\n",
      "passive                   \tpassive                   \tJJ\t3.00\tB1\n",
      "observers                 \tobserver                  \tNNS\t4.00\tB2\n",
      "of                        \tof                        \tIN\t1.00\tA1\n",
      "nature                    \tnature                    \tNN\t2.00\tA2\n",
      "is                        \tis                        \tPOS\t1.00\tA1\n",
      "drama                     \tdrama                     \tNN\t1.00\tA1\n",
      ";                         \t;                         \t:\t0.00\tNone\n",
      "they                      \tthey                      \tPRP\t1.00\tA1\n",
      "are                       \tbe                        \tVBP\t1.00\tA1\n",
      "active                    \tactive                    \tJJ\t3.00\tB1\n",
      "participants              \tparticipant               \tNNS\t3.00\tB1\n",
      "in                        \tin                        \tIN\t1.00\tA1\n",
      "an                        \tan                        \tDT\t1.00\tA1\n",
      "intricate                 \tintricate                 \tJJ\t2.96\tB1\n",
      "dance                     \tdance                     \tNN\t1.00\tA1\n",
      "of                        \tof                        \tIN\t1.00\tA1\n",
      "life                      \tlife                      \tNN\t1.00\tA1\n",
      ".                         \t.                         \t.\t0.00\tNone\n",
      "did                       \tdo                        \tVBD\t1.00\tA1\n",
      "you                       \tyou                       \tPRP\t1.00\tA1\n",
      "know                      \tknow                      \tVB\t1.00\tA1\n",
      "that                      \tthat                      \tIN\t1.75\tA2\n",
      "trees                     \ttree                      \tNNS\t1.00\tA1\n",
      "communicate               \tcommunicate               \tVBP\t2.00\tA2\n",
      "with                      \twith                      \tIN\t1.00\tA1\n",
      "each                      \teach                      \tDT\t1.00\tA1\n",
      "other                     \tother                     \tJJ\t1.50\tA2\n",
      "?                         \t?                         \t.\t0.00\tNone\n",
      "it                        \tit                        \tPRP\t1.00\tA1\n",
      "is                        \tis                        \tVBZ\t1.00\tA1\n",
      "not                       \tnot                       \tRB\t1.00\tA1\n",
      "through                   \tthrough                   \tIN\t1.00\tA1\n",
      "words                     \tword                      \tNNS\t1.00\tA1\n",
      "or                        \tor                        \tCC\t1.00\tA1\n",
      "gestures                  \tgesture                   \tNNS\t3.00\tB1\n",
      "like                      \tlike                      \tIN\t1.00\tA1\n",
      "ours                      \tours                      \tNNS\t1.00\tA1\n",
      ",                         \t,                         \t,\t0.00\tNone\n",
      "but                       \tbut                       \tCC\t1.00\tA1\n",
      "rather                    \trather                    \tRB\t2.00\tA2\n",
      "through                   \tthrough                   \tIN\t1.00\tA1\n",
      "a                         \ta                         \tDT\t1.00\tA1\n",
      "complex                   \tcomplex                   \tJJ\t3.00\tB1\n",
      "network                   \tnetwork                   \tNN\t3.00\tB1\n",
      "of                        \tof                        \tIN\t1.00\tA1\n",
      "fungi                     \tfungus                    \tNNS\t5.19\tC1\n",
      "that                      \tthat                      \tWDT\t1.75\tA2\n",
      "connect                   \tconnect                   \tVBP\t3.00\tB1\n",
      "their                     \ttheir                     \tPRP$\t1.00\tA1\n",
      "roots                     \troot                      \tNNS\t2.00\tA2\n",
      "underground               \tunderground               \tRB\t4.00\tB2\n",
      ".                         \t.                         \t.\t0.00\tNone\n",
      "this                      \tthis                      \tDT\t1.00\tA1\n",
      "network                   \tnetwork                   \tNN\t3.00\tB1\n",
      ",                         \t,                         \t,\t0.00\tNone\n",
      "often                     \toften                     \tRB\t1.00\tA1\n",
      "called                    \tcall                      \tVBD\t1.50\tA2\n",
      "the                       \tthe                       \tDT\t1.00\tA1\n",
      "\"                         \t\"                         \t``\t0.00\tNone\n",
      "wood                      \twood                      \tNN\t2.00\tA2\n",
      "wide                      \twide                      \tJJ\t2.00\tA2\n",
      "web                       \tweb                       \tNN\t2.00\tA2\n",
      ",                         \t,                         \t,\t0.00\tNone\n",
      "\"                         \t\"                         \t''\t0.00\tNone\n",
      "allows                    \tallow                     \tVBZ\t2.00\tA2\n",
      "trees                     \ttree                      \tNNS\t1.00\tA1\n",
      "to                        \tto                        \tTO\t1.00\tA1\n",
      "share                     \tshare                     \tVB\t1.00\tA1\n",
      "nutrients                 \tnutrient                  \tNNS\t3.00\tB1\n",
      ",                         \t,                         \t,\t0.00\tNone\n",
      "water                     \twater                     \tNN\t1.00\tA1\n",
      ",                         \t,                         \t,\t0.00\tNone\n",
      "and                       \tand                       \tCC\t1.00\tA1\n",
      "even                      \teven                      \tRB\t2.00\tA2\n",
      "warnings                  \twarning                   \tNNS\t3.00\tB1\n",
      "about                     \tabout                     \tIN\t1.00\tA1\n",
      "potential                 \tpotential                 \tJJ\t4.00\tB2\n",
      "threats                   \tthreat                    \tNNS\t3.00\tB1\n",
      ".                         \t.                         \t.\t0.00\tNone\n",
      "but                       \tbut                       \tCC\t1.00\tA1\n",
      "trees                     \ttree                      \tNNS\t1.00\tA1\n",
      "are                       \tbe                        \tVBP\t1.00\tA1\n",
      "not                       \tnot                       \tRB\t1.00\tA1\n",
      "just                      \tjust                      \tRB\t1.00\tA1\n",
      "generous                  \tgenerous                  \tJJ\t3.00\tB1\n",
      "benefactors               \tbenefactor                \tNNS\t6.00\tC2\n",
      ";                         \t;                         \t:\t0.00\tNone\n",
      "they                      \tthey                      \tPRP\t1.00\tA1\n",
      "are                       \tbe                        \tVBP\t1.00\tA1\n",
      "also                      \talso                      \tRB\t1.00\tA1\n",
      "masters                   \tmaster                    \tNNS\t4.00\tB2\n",
      "of                        \tof                        \tIN\t1.00\tA1\n",
      "adaptation                \tadaptation                \tNN\t3.71\tB2\n",
      ".                         \t.                         \t.\t0.00\tNone\n",
      "take                      \ttake                      \tVB\t1.00\tA1\n",
      "the                       \tthe                       \tDT\t1.00\tA1\n",
      "mighty                    \tmighty                    \tJJ\t4.00\tB2\n",
      "sequoias                  \tsequoia                   \tNNS\t6.00\tC2\n",
      ",                         \t,                         \t,\t0.00\tNone\n",
      "for                       \tfor                       \tIN\t1.00\tA1\n",
      "example                   \texample                   \tNN\t1.00\tA1\n",
      ",                         \t,                         \t,\t0.00\tNone\n",
      "towering                  \ttower                     \tVBG\t1.00\tA1\n",
      "giants                    \tgiant                     \tNNS\t3.00\tB1\n",
      "that                      \tthat                      \tWDT\t1.75\tA2\n",
      "have                      \thave                      \tVBP\t1.00\tA1\n",
      "stood                     \tstand                     \tVBN\t1.50\tA2\n",
      "the                       \tthe                       \tDT\t1.00\tA1\n",
      "test                      \ttest                      \tNN\t1.00\tA1\n",
      "of                        \tof                        \tIN\t1.00\tA1\n",
      "time                      \ttime                      \tNN\t1.00\tA1\n",
      "for                       \tfor                       \tIN\t1.00\tA1\n",
      "thousands                 \tthousand                  \tNNS\t2.00\tA2\n",
      "of                        \tof                        \tIN\t1.00\tA1\n",
      "years                     \tyear                      \tNNS\t1.00\tA1\n",
      ".                         \t.                         \t.\t0.00\tNone\n",
      "these                     \tthese                     \tDT\t1.00\tA1\n",
      "giants                    \tgiant                     \tNNS\t3.00\tB1\n",
      "have                      \thave                      \tVBP\t1.00\tA1\n",
      "evolved                   \tevolve                    \tVBN\t4.00\tB2\n",
      "thick                     \tthick                     \tJJ\t1.00\tA1\n",
      ",                         \t,                         \t,\t0.00\tNone\n",
      "fire                      \tfire                      \tNN\t1.00\tA1\n",
      "-                         \t-                         \tHYPH\t0.00\tNone\n",
      "resistant                 \tresistant                 \tJJ\t3.59\tB2\n",
      "bark                      \tbark                      \tNN\t3.00\tB1\n",
      "to                        \tto                        \tTO\t1.00\tA1\n",
      "withstand                 \twithstand                 \tVB\t5.12\tC1\n",
      "the                       \tthe                       \tDT\t1.00\tA1\n",
      "frequent                  \tfrequent                  \tJJ\t3.00\tB1\n",
      "wildfires                 \twildfire                  \tNNS\t6.00\tC2\n",
      "of                        \tof                        \tIN\t1.00\tA1\n",
      "their                     \ttheir                     \tPRP$\t1.00\tA1\n",
      "native                    \tnative                    \tJJ\t2.00\tA2\n",
      "california                \tcalifornia                \tNNP\t6.00\tC2\n",
      ".                         \t.                         \t.\t0.00\tNone\n",
      "and                       \tand                       \tCC\t1.00\tA1\n",
      "speaking                  \tspeak                     \tVBG\t1.00\tA1\n",
      "of                        \tof                        \tIN\t1.00\tA1\n",
      "longevity                 \tlongevity                 \tNN\t5.97\tC2\n",
      ",                         \t,                         \t,\t0.00\tNone\n",
      "did                       \tdo                        \tVBD\t1.00\tA1\n",
      "you                       \tyou                       \tPRP\t1.00\tA1\n",
      "know                      \tknow                      \tVB\t1.00\tA1\n",
      "that                      \tthat                      \tIN\t1.75\tA2\n",
      "some                      \tsome                      \tDT\t1.00\tA1\n",
      "trees                     \ttree                      \tNNS\t1.00\tA1\n",
      "have                      \thave                      \tVBP\t1.00\tA1\n",
      "been                      \tbe                        \tVBN\t2.00\tA2\n",
      "around                    \taround                    \tRB\t2.00\tA2\n",
      "for                       \tfor                       \tIN\t1.00\tA1\n",
      "centuries                 \tcentury                   \tNNS\t2.00\tA2\n",
      ",                         \t,                         \t,\t0.00\tNone\n",
      "witnessing                \twitness                   \tVBG\t3.50\tB2\n",
      "history                   \thistory                   \tNN\t1.00\tA1\n",
      "unfold                    \tunfold                    \tNN\t3.00\tB1\n",
      "?                         \t?                         \t.\t0.00\tNone\n",
      "the                       \tthe                       \tDT\t1.00\tA1\n",
      "ancient                   \tancient                   \tJJ\t2.00\tA2\n",
      "bristlecone               \tbristlecone               \tNN\t6.00\tC2\n",
      "pines                     \tpine                      \tNNS\t4.00\tB2\n",
      "of                        \tof                        \tIN\t1.00\tA1\n",
      "the                       \tthe                       \tDT\t1.00\tA1\n",
      "american                  \tamerican                  \tNNP\t1.24\tA1\n",
      "west                      \twest                      \tNNP\t2.00\tA2\n",
      ",                         \t,                         \t,\t0.00\tNone\n",
      "for                       \tfor                       \tIN\t1.00\tA1\n",
      "instance                  \tinstance                  \tNN\t3.00\tB1\n",
      ",                         \t,                         \t,\t0.00\tNone\n",
      "can                       \tcan                       \tMD\t1.00\tA1\n",
      "live                      \tlive                      \tVB\t1.00\tA1\n",
      "for                       \tfor                       \tIN\t1.00\tA1\n",
      "over                      \tover                      \tIN\t1.00\tA1\n",
      "5,000                     \t5,000                     \tCD\t0.00\tNone\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "print(f'{\"WORD\".ljust(26)}\\t{\"LEMMA\".ljust(26)}\\tPOS\\tLEVEL\\tCEFR')\n",
    "print('-' * 85)\n",
    "for token in level_tokens:\n",
    "    word, lemma, pos, level = token\n",
    "    if pos != '_SP':\n",
    "        print(f'{word.ljust(26)}\\t{lemma.ljust(26)}\\t{pos}\\t{\"{:.2f}\".format(level)}\\t{DIFFICULTY_MAPPING_REVERSE.get(round(level))}')\n",
    "\n",
    "        counter += 1\n",
    "        if counter >= 200:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CEFR statistic (total words):\n",
      "A1: 136\n",
      "A2: 37\n",
      "B1: 27\n",
      "B2: 11\n",
      "C1: 2\n",
      "C2: 7\n"
     ]
    }
   ],
   "source": [
    "difficulty_levels_count = get_word_level_count_statistic(level_tokens)\n",
    "\n",
    "print('CEFR statistic (total words):')\n",
    "for i in range(1, 7):\n",
    "    print(f'{DIFFICULTY_MAPPING_REVERSE.get(i)}: {difficulty_levels_count[i - 1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CEFR statistic (unique words):\n",
      "A1: 69\n",
      "A2: 34\n",
      "B1: 23\n",
      "B2: 11\n",
      "C1: 2\n",
      "C2: 7\n"
     ]
    }
   ],
   "source": [
    "difficulty_levels_count_unique = get_word_level_count_statistic_unique(level_tokens)\n",
    "\n",
    "print('CEFR statistic (unique words):')\n",
    "for i in range(1, 7):\n",
    "    print(f'{DIFFICULTY_MAPPING_REVERSE.get(i)}: {difficulty_levels_count_unique[i - 1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not found words: 0\n"
     ]
    }
   ],
   "source": [
    "not_found_words_set = get_not_found_words(level_tokens)\n",
    "\n",
    "not_found_words_list = list(not_found_words_set)\n",
    "not_found_words_list.sort()\n",
    "\n",
    "print('Not found words:', len(not_found_words_list))\n",
    "\n",
    "if len(not_found_words_list):\n",
    "    print('\\n'.join(not_found_words_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tWords with level B2 and higher: 17\n",
      "mighty                     JJ     4.00   B2\n",
      "potential                  JJ     4.00   B2\n",
      "bristlecone                NN     6.00   C2\n",
      "living                     NN     4.00   B2\n",
      "longevity                  NN     5.97   C2\n",
      "california                 NNP    6.00   C2\n",
      "benefactors                NNS    6.00   C2\n",
      "fungi                      NNS    5.19   C1\n",
      "masters                    NNS    4.00   B2\n",
      "observers                  NNS    4.00   B2\n",
      "pines                      NNS    4.00   B2\n",
      "sequoias                   NNS    6.00   C2\n",
      "wildfires                  NNS    6.00   C2\n",
      "underground                RB     4.00   B2\n",
      "withstand                  VB     5.12   C1\n",
      "evolved                    VBN    4.00   B2\n",
      "thrives                    VBZ    5.86   C2\n"
     ]
    }
   ],
   "source": [
    "desired_level_words_set = filter_for_desired_level(level_tokens, 4)\n",
    "\n",
    "desired_level_words_list = list(desired_level_words_set)\n",
    "desired_level_words_list.sort(key=lambda x: (x[2], x[0]))\n",
    "\n",
    "print('\\tWords with level B2 and higher:', len(desired_level_words_list))\n",
    "for word_data in desired_level_words_list:\n",
    "    word, _, pos, level = word_data\n",
    "    print(word.lower().ljust(26), pos.ljust(6), \"{:.2f}\".format(level).ljust(6), DIFFICULTY_MAPPING_REVERSE.get(round(level)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
